{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params \n",
    "\n",
    "original_image_size = (720,1280,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the input images\n",
    "input_image_size = (416,416,3)\n",
    "\n",
    "# bounding boxes per cell\n",
    "BB_per_cell = 3 \n",
    "\n",
    "# number of classes in the dataset\n",
    "Classes = 5\n",
    "\n",
    "# Batch size\n",
    "batch_ = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weight matrix initialization whenever using relu\n",
    "initializer_ = tf.keras.initializers.he_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Build_model(initializer_, input_image_size, BB_per_cell, Classes, batch_, model_name):\n",
    "    \n",
    "    # input lauer\n",
    "    input_layer = tf.keras.layers.Input(shape=input_image_size, batch_size=batch_, name=\"input\")\n",
    "\n",
    "    # down_sampling\n",
    "    conv_1 = tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1),\n",
    "                 activation='relu', kernel_initializer=initializer_, padding=\"same\", name=\"conv_1\")(input_layer)\n",
    "\n",
    "    pooling_1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"pool_1\")(conv_1)\n",
    "    \n",
    "    batch_norm_1 = tf.keras.layers.BatchNormalization()(pooling_1)\n",
    "\n",
    "    conv_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), strides=(1,1),\n",
    "                 activation='relu', kernel_initializer=initializer_,padding=\"same\", name=\"conv_2\")(batch_norm_1)\n",
    "    \n",
    "    pooling_2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"pool_2\")(conv_2)\n",
    "    \n",
    "    batch_norm_2 = tf.keras.layers.BatchNormalization()(pooling_2)\n",
    "\n",
    "    conv_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), strides=(1,1),\n",
    "                 activation='relu', kernel_initializer=initializer_,padding=\"same\", name=\"conv_3\")(batch_norm_2)\n",
    "    \n",
    "    pooling_3 = tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"pool_3\")(conv_3)\n",
    "    \n",
    "    batch_norm_3 = tf.keras.layers.BatchNormalization()(pooling_3)\n",
    "\n",
    "    conv_4 = tf.keras.layers.Conv2D(filters=BB_per_cell*(5+Classes), kernel_size=(3,3), strides=(1,1),\n",
    "                 activation='relu', kernel_initializer=initializer_,padding=\"same\", name=\"conv_4\")(batch_norm_3)\n",
    "    \n",
    "    pooling_4 = tf.keras.layers.MaxPool2D(pool_size=(2,2), name=\"detection_1\")(conv_4)\n",
    "    \n",
    "    batch_norm_4 = tf.keras.layers.BatchNormalization()(pooling_4)\n",
    "\n",
    "    # up sampling\n",
    "\n",
    "    # up_sampling_1 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation=\"nearest\", name=\"up_sampling_1\")(pooling_4)\n",
    "    # \n",
    "    # concat_layer_1 = tf.keras.layers.Concatenate(name=\"detection_2\")([conv_4,up_sampling_1])\n",
    "    # \n",
    "    # conv_5 = tf.keras.layers.Conv2D(filters=BB_per_cell*(5+Classes), kernel_size=(1,1), strides=(1,1),\n",
    "    #              activation='relu', kernel_initializer=relu_initializer, name=\"detection_2\")(up_sampling_1)\n",
    "    # \n",
    "    # up_sampling_2 = tf.keras.layers.UpSampling2D(size=(2, 2), interpolation=\"nearest\", name=\"up_sampling_2\")(conv_5)\n",
    "    # \n",
    "    # conv_6 = tf.keras.layers.Conv2D(filters=BB_per_cell*(5+Classes), kernel_size=(1,1), strides=(1,1),\n",
    "    #              activation='relu', kernel_initializer=relu_initializer, name=\"detection_3\")(up_sampling_2)\n",
    "    # \n",
    "    \n",
    "    return tf.keras.Model(inputs=input_layer, outputs=[pooling_4], name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Build_model(initializer_, input_image_size, BB_per_cell, Classes, batch_, \"My_SSD_Detector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"My_SSD_Detector\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(16, 416, 416, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (16, 416, 416, 256)       7168      \n",
      "_________________________________________________________________\n",
      "pool_1 (MaxPooling2D)        (16, 208, 208, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (16, 208, 208, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_2 (Conv2D)              (16, 208, 208, 128)       295040    \n",
      "_________________________________________________________________\n",
      "pool_2 (MaxPooling2D)        (16, 104, 104, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (16, 104, 104, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_3 (Conv2D)              (16, 104, 104, 64)        73792     \n",
      "_________________________________________________________________\n",
      "pool_3 (MaxPooling2D)        (16, 52, 52, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (16, 52, 52, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv_4 (Conv2D)              (16, 52, 52, 30)          17310     \n",
      "_________________________________________________________________\n",
      "detection_1 (MaxPooling2D)   (16, 26, 26, 30)          0         \n",
      "=================================================================\n",
      "Total params: 395,102\n",
      "Trainable params: 394,206\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the tensorbard directory\n",
    "import os \n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir(root_logdir):\n",
    "    import time\n",
    "    run_dir = time.strftime(\"run%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir,run_dir)\n",
    "\n",
    "run_logdir = get_run_logdir(root_logdir)\n",
    "\n",
    "# tensorboard callback\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf_gpu]",
   "language": "python",
   "name": "conda-env-tf_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "202px",
    "width": "160px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
